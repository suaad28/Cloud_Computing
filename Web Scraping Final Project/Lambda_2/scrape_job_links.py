import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import time


def scrape_job_links(list_of_all_URLs):
    """
    function to scrape individual job postings
    (via another function 'scrape_job_info')

    gets HTML of each search page from the list
    generated by the function 'get_all_search_pages',
    parses links to individual job postings
    from search results pages, and feeds them
    to function 'scrape_job_info'

    Input arguments: 'List_of_all_URLs'   -- list  -- list containing URLs of all pages with job search results
    """
    # loop over all pages in 'List_of_all_URLs' to extract links to each job posting
    job_url_list = []
    job_search_results = []
    for page_url in list_of_all_URLs:

        # get the HTML of the search results page
        # page = requests.get(page_url)
        ####################
        import urllib.request

        try:
            with urllib.request.urlopen(page_url) as r:
                # content = r.read().decode('utf-8'))
                content = r.read()
                time.sleep(6)
        except urllib.error.URLError as e:
            print(e.reason)
        ####################        

        # make a soup out of the HTML
        soup = BeautifulSoup(content, 'lxml')
        # print("\n Inside soup type - ")
        #print(type(soup), ":\n", soup, "\n\n")               

        # find all <div> tags containing each job posting links and feed them to the function 'scrape_job_info'('div', {'class': 'pagination'})

        print("\nEntering job link for loop: \n")

        for table in soup.findAll(class_=['mosaic-zone']):
            for a in table.find_all('a'):
                all_href = a.get('href') 
                if (all_href.startswith("/rc/")):
                    job_search_results.append(all_href)       

        
        for job in job_search_results:

            # extract the individual job posting link from a <div> tag
            
            new_url = "https://www.indeed.ca" + job
            #job_url = urlparse(new_url)

            # if len(job_url.geturl()) < 300:all_href
            #job_url_list.append(job_url.geturl())
            job_url_list.append(new_url)

    print("\n job_url_list:",job_url_list)
    return job_url_list
